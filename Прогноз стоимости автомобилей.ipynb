{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a539580c",
   "metadata": {},
   "source": [
    "Целью данного проекта является разработка модели предсказания стоимости автомобиля на вторичном рынке.\n",
    "\n",
    "В качестве обучающих данных имеется информация о продажах (~440000) автомобилей с аукционов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ebba40",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fcbc3",
   "metadata": {},
   "source": [
    "Импортируем библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1bfbfc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from statistics import mode\n",
    "import jellyfish\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from vininfo import Vin\n",
    "\n",
    "pd.set_option('display.float_format', '{:,.0f}'.format)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969519f",
   "metadata": {},
   "source": [
    "Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b8274805",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/a.babaev/Desktop/kaggle/train.csv')\n",
    "test = pd.read_csv('/Users/a.babaev/Desktop/kaggle/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5c0f5b76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>trim</th>\n",
       "      <th>body</th>\n",
       "      <th>transmission</th>\n",
       "      <th>vin</th>\n",
       "      <th>state</th>\n",
       "      <th>condition</th>\n",
       "      <th>odometer</th>\n",
       "      <th>color</th>\n",
       "      <th>interior</th>\n",
       "      <th>seller</th>\n",
       "      <th>sellingprice</th>\n",
       "      <th>saledate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Edge</td>\n",
       "      <td>SEL</td>\n",
       "      <td>suv</td>\n",
       "      <td>automatic</td>\n",
       "      <td>2fmdk3jc4bba41556</td>\n",
       "      <td>md</td>\n",
       "      <td>4</td>\n",
       "      <td>111,041</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>santander consumer</td>\n",
       "      <td>12500</td>\n",
       "      <td>Tue Jun 02 2015 02:30:00 GMT-0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Fusion</td>\n",
       "      <td>SE</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>automatic</td>\n",
       "      <td>3fa6p0h75er208976</td>\n",
       "      <td>mo</td>\n",
       "      <td>4</td>\n",
       "      <td>31,034</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>ars/avis budget group</td>\n",
       "      <td>14500</td>\n",
       "      <td>Wed Feb 25 2015 02:00:00 GMT-0800 (PST)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Sentra</td>\n",
       "      <td>2.0 SL</td>\n",
       "      <td>sedan</td>\n",
       "      <td>automatic</td>\n",
       "      <td>3n1ab6ap4cl698412</td>\n",
       "      <td>nj</td>\n",
       "      <td>2</td>\n",
       "      <td>35,619</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>nissan-infiniti lt</td>\n",
       "      <td>9100</td>\n",
       "      <td>Wed Jun 10 2015 02:30:00 GMT-0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>HUMMER</td>\n",
       "      <td>H2</td>\n",
       "      <td>Base</td>\n",
       "      <td>suv</td>\n",
       "      <td>automatic</td>\n",
       "      <td>5grgn23u93h101360</td>\n",
       "      <td>tx</td>\n",
       "      <td>3</td>\n",
       "      <td>131,301</td>\n",
       "      <td>gold</td>\n",
       "      <td>beige</td>\n",
       "      <td>wichita falls ford lin inc</td>\n",
       "      <td>13300</td>\n",
       "      <td>Wed Jun 17 2015 03:00:00 GMT-0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Fusion</td>\n",
       "      <td>SEL</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>automatic</td>\n",
       "      <td>3fahp08z17r268380</td>\n",
       "      <td>md</td>\n",
       "      <td>2</td>\n",
       "      <td>127,709</td>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>purple heart</td>\n",
       "      <td>1300</td>\n",
       "      <td>Tue Feb 03 2015 04:00:00 GMT-0800 (PST)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    make   model    trim   body transmission                vin state  \\\n",
       "0  2011    Ford    Edge     SEL    suv    automatic  2fmdk3jc4bba41556    md   \n",
       "1  2014    Ford  Fusion      SE  Sedan    automatic  3fa6p0h75er208976    mo   \n",
       "2  2012  Nissan  Sentra  2.0 SL  sedan    automatic  3n1ab6ap4cl698412    nj   \n",
       "3  2003  HUMMER      H2    Base    suv    automatic  5grgn23u93h101360    tx   \n",
       "4  2007    Ford  Fusion     SEL  Sedan    automatic  3fahp08z17r268380    md   \n",
       "\n",
       "   condition  odometer  color interior                      seller  \\\n",
       "0          4   111,041  black    black          santander consumer   \n",
       "1          4    31,034  black    black       ars/avis budget group   \n",
       "2          2    35,619  black    black          nissan-infiniti lt   \n",
       "3          3   131,301   gold    beige  wichita falls ford lin inc   \n",
       "4          2   127,709  black    black                purple heart   \n",
       "\n",
       "   sellingprice                                 saledate  \n",
       "0         12500  Tue Jun 02 2015 02:30:00 GMT-0700 (PDT)  \n",
       "1         14500  Wed Feb 25 2015 02:00:00 GMT-0800 (PST)  \n",
       "2          9100  Wed Jun 10 2015 02:30:00 GMT-0700 (PDT)  \n",
       "3         13300  Wed Jun 17 2015 03:00:00 GMT-0700 (PDT)  \n",
       "4          1300  Tue Feb 03 2015 04:00:00 GMT-0800 (PST)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81a4ff",
   "metadata": {},
   "source": [
    "Согласно документации к данным:\n",
    "\n",
    "- `year` - год производства\n",
    "- `make` - производитель\n",
    "- `model` - модель\n",
    "- `trim` - модификация\n",
    "- `body` - тип кузова\n",
    "- `transmission` - тип КПП\n",
    "- `vin` - идентификатор\n",
    "- `state` - штат регистрации\n",
    "- `condition` - состояние по шкале (1-5)\n",
    "- `odometer` - пробег в милях\n",
    "- `color` - цвет кузова\n",
    "- `interior` - цвет интерьера\n",
    "- `seller` - продавец\n",
    "- `sellingprice` - стоимость продажи\n",
    "- `saledate` - дата продажи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c4316",
   "metadata": {},
   "source": [
    "Изучим общую информацию о таблицах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4f6cc605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440236 entries, 0 to 440235\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   year          440236 non-null  int64  \n",
      " 1   make          432193 non-null  object \n",
      " 2   model         432113 non-null  object \n",
      " 3   trim          431899 non-null  object \n",
      " 4   body          429843 non-null  object \n",
      " 5   transmission  388775 non-null  object \n",
      " 6   vin           440236 non-null  object \n",
      " 7   state         440236 non-null  object \n",
      " 8   condition     430831 non-null  float64\n",
      " 9   odometer      440167 non-null  float64\n",
      " 10  color         439650 non-null  object \n",
      " 11  interior      439650 non-null  object \n",
      " 12  seller        440236 non-null  object \n",
      " 13  sellingprice  440236 non-null  int64  \n",
      " 14  saledate      440236 non-null  object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 50.4+ MB\n",
      "\n",
      "\n",
      "test :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110060 entries, 0 to 110059\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   year          110060 non-null  int64  \n",
      " 1   make          107999 non-null  object \n",
      " 2   model         107981 non-null  object \n",
      " 3   trim          107946 non-null  object \n",
      " 4   body          107466 non-null  object \n",
      " 5   transmission  97048 non-null   object \n",
      " 6   vin           110060 non-null  object \n",
      " 7   state         110060 non-null  object \n",
      " 8   condition     107681 non-null  float64\n",
      " 9   odometer      110041 non-null  float64\n",
      " 10  color         109902 non-null  object \n",
      " 11  interior      109902 non-null  object \n",
      " 12  seller        110060 non-null  object \n",
      " 13  saledate      110060 non-null  object \n",
      "dtypes: float64(2), int64(1), object(11)\n",
      "memory usage: 11.8+ MB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = [train, test]\n",
    "dfs_name = ['train', 'test']\n",
    "\n",
    "for i, j in zip(dfs, dfs_name):\n",
    "    print(j, ':')\n",
    "    i.info()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3fcd8edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в таблице train:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "year                0\n",
       "make             8043\n",
       "model            8123\n",
       "trim             8337\n",
       "body            10393\n",
       "transmission    51461\n",
       "vin                 0\n",
       "state               0\n",
       "condition        9405\n",
       "odometer           69\n",
       "color             586\n",
       "interior          586\n",
       "seller              0\n",
       "sellingprice        0\n",
       "saledate            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Пропуски в таблице test:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "year                0\n",
       "make             2061\n",
       "model            2079\n",
       "trim             2114\n",
       "body             2594\n",
       "transmission    13012\n",
       "vin                 0\n",
       "state               0\n",
       "condition        2379\n",
       "odometer           19\n",
       "color             158\n",
       "interior          158\n",
       "seller              0\n",
       "saledate            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = [train, test]\n",
    "dfs_name = ['train', 'test']\n",
    "\n",
    "for i, j in zip(dfs, dfs_name):\n",
    "    print('Пропуски в таблице ', j, ':', sep='')\n",
    "    display(i.isna().sum())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a2fd2",
   "metadata": {},
   "source": [
    "В датафреймах присутствуют пропуски данных.\n",
    "\n",
    "Проверим наличие дубликатов в датафреймах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0fd7a44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов в таблице train: 0\n",
      "Количество дубликатов в таблице test: 0\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(dfs, dfs_name):\n",
    "    print('Количество дубликатов в таблице ', j,': ', i.duplicated().sum(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a446b2a",
   "metadata": {},
   "source": [
    "Явные дубликаты отсутствуют.\n",
    "\n",
    "Изучим распределение количественных переменных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ac6c2275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>440,236</td>\n",
       "      <td>2,010</td>\n",
       "      <td>4</td>\n",
       "      <td>1,982</td>\n",
       "      <td>2,007</td>\n",
       "      <td>2,012</td>\n",
       "      <td>2,013</td>\n",
       "      <td>2,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>430,831</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odometer</th>\n",
       "      <td>440,167</td>\n",
       "      <td>68,344</td>\n",
       "      <td>53,542</td>\n",
       "      <td>1</td>\n",
       "      <td>28,258</td>\n",
       "      <td>52,098</td>\n",
       "      <td>99,272</td>\n",
       "      <td>999,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sellingprice</th>\n",
       "      <td>440,236</td>\n",
       "      <td>13,592</td>\n",
       "      <td>9,751</td>\n",
       "      <td>1</td>\n",
       "      <td>6,900</td>\n",
       "      <td>12,100</td>\n",
       "      <td>18,200</td>\n",
       "      <td>230,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count   mean    std   min    25%    50%    75%     max\n",
       "year         440,236  2,010      4 1,982  2,007  2,012  2,013   2,015\n",
       "condition    430,831      3      1     1      3      4      4       5\n",
       "odometer     440,167 68,344 53,542     1 28,258 52,098 99,272 999,999\n",
       "sellingprice 440,236 13,592  9,751     1  6,900 12,100 18,200 230,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>110,060</td>\n",
       "      <td>2,010</td>\n",
       "      <td>4</td>\n",
       "      <td>1,982</td>\n",
       "      <td>2,007</td>\n",
       "      <td>2,012</td>\n",
       "      <td>2,013</td>\n",
       "      <td>2,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>107,681</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odometer</th>\n",
       "      <td>110,041</td>\n",
       "      <td>68,076</td>\n",
       "      <td>53,524</td>\n",
       "      <td>1</td>\n",
       "      <td>28,314</td>\n",
       "      <td>51,922</td>\n",
       "      <td>98,854</td>\n",
       "      <td>999,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count   mean    std   min    25%    50%    75%     max\n",
       "year      110,060  2,010      4 1,982  2,007  2,012  2,013   2,015\n",
       "condition 107,681      3      1     1      3      4      4       5\n",
       "odometer  110,041 68,076 53,524     1 28,314 51,922 98,854 999,999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, j in zip(dfs, dfs_name):\n",
    "    print(j, ':', sep='')\n",
    "    display(i.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7dae0",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd735d",
   "metadata": {},
   "source": [
    "Объединим данные в единый датафрейм для предобработки данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6b31bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], keys=['train', 'test']).reset_index().drop(columns=['level_1']).rename(columns={'level_0':'data_type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0f4189cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведем столбец с датой в формат даты:\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], utc=True).dt.tz_localize(None)\n",
    "\n",
    "# добавим столбцы с годом и месяцем продажи:\n",
    "df['sale_year'] = df['saledate'].dt.year\n",
    "df['sale_month'] = df['saledate'].dt.month\n",
    "\n",
    "# приведем категориальный переменные к нижнему регистру :\n",
    "cat_features = df.select_dtypes(include=['object']).columns.to_list()\n",
    "cat_features.remove('data_type')\n",
    "cat_features.remove('vin')\n",
    "cat_features.remove('seller')\n",
    "df[cat_features] = df[cat_features].apply(lambda x: x.str.lower())\n",
    "df[cat_features] = df[cat_features].apply(lambda x: x.str.replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c69ab3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# унифицируем значения в столбце body:\n",
    "df.loc[df['body'].str.contains('convert', na=False), 'body'] = 'convertible'\n",
    "df.loc[df['body'].str.contains('sedan', na=False), 'body'] = 'sedan'\n",
    "df.loc[df['body'].str.contains('cab', na=False), 'body'] = 'cab'\n",
    "df.loc[df['body'].str.contains('van', na=False), 'body'] = 'van'\n",
    "df.loc[df['body'].str.contains('wagon', na=False), 'body'] = 'wagon'\n",
    "df.loc[df['body'].str.contains('coupe', na=False), 'body'] = 'coupe'\n",
    "df.loc[df['body'].str.contains('koup', na=False), 'body'] = 'coupe'\n",
    "\n",
    "# унифицируем значения в столбце make:\n",
    "df.loc[df['make'].str.contains('fordtruck', na=False), 'make'] = 'ford' \n",
    "df.loc[df['make'].str.contains('chevtruck', na=False), 'make'] = 'chevrolet'\n",
    "df.loc[df['make'].str.contains('gmctruck', na=False), 'make'] = 'gmc'\n",
    "df.loc[df['make'].str.contains('vw', na=False), 'make'] = 'volkswagen'\n",
    "df.loc[df['make'].str.contains('mercedes-benz', na=False), 'make'] = 'mercedes'\n",
    "\n",
    "# заменим '-' на пропуски:\n",
    "df['color'] = df['color'].replace('—', np.nan)\n",
    "df['interior'] = df['interior'].replace('—', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "50b338ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце make: 10104\n",
      "Количество пропусков в столбце make: 22\n"
     ]
    }
   ],
   "source": [
    "# используем wmi-код из vin номера для заполнения пропусков в столбце make:\n",
    "print('Количество пропусков в столбце make:', df['make'].isna().sum())\n",
    "\n",
    "df['wmi_code'] = df['vin'].str[:3]\n",
    "wmi_dict = df.groupby(['wmi_code', 'make'], as_index=False).agg({'vin':'count'})\n",
    "df.loc[df['make'].isna(), 'make'] = df[df['make'].isna()]['wmi_code'].map(dict(zip(wmi_dict['wmi_code'], wmi_dict['make'])))\n",
    "df = df.drop('wmi_code', axis=1)\n",
    "\n",
    "print('Количество пропусков в столбце make:', df['make'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9ff327c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце make: 0\n"
     ]
    }
   ],
   "source": [
    "# для заполнения оставшихся пропусков используем библиотеку vininfo:\n",
    "vin = []\n",
    "manufacture = []\n",
    "\n",
    "for i in df[df['make'].isna()]['vin'].unique():\n",
    "    vin.append(i)\n",
    "    manufacture.append(Vin(i).manufacturer)\n",
    "    \n",
    "manufacture_dict = pd.DataFrame(list(zip(vin, manufacture)),columns=['vin', 'make'])\n",
    "manufacture_dict['make'] = manufacture_dict['make'].str.lower().str.replace(\" \", \"\")\n",
    "df.loc[df['make'].isna(), 'make'] = df[df['make'].isna()]['vin'].map(dict(zip(manufacture_dict['vin'], manufacture_dict['make'])))\n",
    "\n",
    "print('Количество пропусков в столбце make:', df['make'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "39f8c12e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце model: 10202\n",
      "Количество пропусков в столбце model: 176\n"
     ]
    }
   ],
   "source": [
    "# используем wmi-код и код модели из vin номера для заполнения пропусков в столбце model:\n",
    "print('Количество пропусков в столбце model:', df['model'].isna().sum())\n",
    "\n",
    "df['model_code'] = df['vin'].str[:5]\n",
    "model_dict = df.groupby(['model_code', 'model'], as_index=False).agg({'vin':'count'})\n",
    "df.loc[df['model'].isna(), 'model'] = df[df['model'].isna()]['model_code'].map(dict(zip(model_dict['model_code'], model_dict['model'])))\n",
    "df = df.drop('model_code', axis=1)\n",
    "\n",
    "print('Количество пропусков в столбце model:', df['model'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4ba52b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце trim: 10451\n",
      "Количество пропусков в столбце trim: 348\n"
     ]
    }
   ],
   "source": [
    "# используем wmi-код и код модели из vin номера для заполнения пропусков в столбце trim:\n",
    "print('Количество пропусков в столбце trim:', df['trim'].isna().sum())\n",
    "\n",
    "df['trim_code'] = df['vin'].str[:6]\n",
    "trim_dict = df.groupby(['trim_code', 'trim'], as_index=False).agg({'vin':'count'})\n",
    "df.loc[df['trim'].isna(), 'trim'] = df[df['trim'].isna()]['trim_code'].map(dict(zip(trim_dict['trim_code'], trim_dict['trim'])))\n",
    "df = df.drop('trim_code', axis=1)\n",
    "\n",
    "print('Количество пропусков в столбце trim:', df['trim'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "df486543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце transmission: 64473\n",
      "Количество пропусков в столбце transmission: 105\n"
     ]
    }
   ],
   "source": [
    "# заполним пропуски в столбце transmission наиболее популярным типом трансмиссии для модели:\n",
    "print('Количество пропусков в столбце transmission:', df['transmission'].isna().sum())\n",
    "\n",
    "transmission_dict = df.groupby(['model', 'transmission'], as_index=False).agg({'vin':'count'}).sort_values(by='vin', ascending=False)\n",
    "transmission_dict = transmission_dict.drop_duplicates(subset='model', keep='first')\n",
    "df.loc[df['transmission'].isna(), 'transmission'] = df[df['transmission'].isna()]['model'].map(dict(zip(transmission_dict['model'], transmission_dict['transmission'])))\n",
    "\n",
    "print('Количество пропусков в столбце transmission:', df['transmission'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "48968dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце transmission: 105\n",
      "Количество пропусков в столбце transmission: 0\n"
     ]
    }
   ],
   "source": [
    "# заполним оставшиеся пропуски наиболее популярным типом трансмиссии для года выпуска:\n",
    "print('Количество пропусков в столбце transmission:', df['transmission'].isna().sum())\n",
    "\n",
    "for year in df[df['transmission'].isna()]['year'].unique(): \n",
    "    mode_transmission = df.loc[df['year'] == year, 'transmission'].mode()[0]\n",
    "    df.loc[(df['transmission'].isna()) & (df['year'] == year), 'transmission'] = mode_transmission\n",
    "\n",
    "print('Количество пропусков в столбце transmission:', df['transmission'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "28732f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце odometer: 88\n",
      "Количество пропусков в столбце odometer: 0\n"
     ]
    }
   ],
   "source": [
    "# заполним пропуски в столбце odometer средним пробегом по автомобилям аналогичного года выпуска:\n",
    "print('Количество пропусков в столбце odometer:', df['odometer'].isna().sum())\n",
    "\n",
    "for year in df[df['odometer'].isna()]['year'].unique(): \n",
    "    avg_distance = df.loc[df['year'] == year, 'odometer'].mean()\n",
    "    df.loc[(df['odometer'].isna()) & (df['year'] == year), 'odometer'] = avg_distance\n",
    "\n",
    "print('Количество пропусков в столбце odometer:', df['odometer'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "594ea480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце condition: 11784\n",
      "Количество пропусков в столбце condition: 0\n"
     ]
    }
   ],
   "source": [
    "# заполним пропуски в столбце condition средним значением по автомобилям аналогичным пробегом:\n",
    "print('Количество пропусков в столбце condition:', df['condition'].isna().sum())\n",
    "\n",
    "for distance in round(df['odometer'], -3).unique():\n",
    "\n",
    "    avg_condition = df.loc[round(df['odometer'], -3) == round(distance, -3), 'condition'].mean()\n",
    "    df.loc[(df['condition'].isna()) & (round(df['odometer'], -3) == round(distance, -3)), 'condition'] = avg_condition \n",
    "    \n",
    "    avg_condition = df.loc[round(df['odometer'], -4) == round(distance, -4), 'condition'].mean()\n",
    "    df.loc[(df['condition'].isna()) & (round(df['odometer'], -4) == round(distance, -4)), 'condition'] = avg_condition  \n",
    "    \n",
    "print('Количество пропусков в столбце condition:', df['condition'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "29c814b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце color: 25212\n",
      "Количество пропусков в столбце color: 0\n"
     ]
    }
   ],
   "source": [
    "# заполним пропуски в столбце color самым популярным значением по модели:\n",
    "print('Количество пропусков в столбце color:', df['color'].isna().sum())\n",
    "\n",
    "for model in df[df['color'].isna()]['model'].unique():\n",
    "    try:\n",
    "        mode_color = df.loc[df['model'] == model, 'color'].mode()[0]\n",
    "        df.loc[(df['color'].isna()) & (df['model'] == model), 'color'] = mode_color\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "imputer = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
    "imputer = imputer.fit(df[['color']])\n",
    "df[['color']] = imputer.transform(df[['color']])\n",
    "\n",
    "print('Количество пропусков в столбце color:', df['color'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0cb06764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце interior: 17687\n",
      "Количество пропусков в столбце interior: 0\n"
     ]
    }
   ],
   "source": [
    "# заполним пропуски в столбце interior самым популярным значением по модели:\n",
    "print('Количество пропусков в столбце interior:', df['interior'].isna().sum())\n",
    "\n",
    "for model in df[df['interior'].isna()]['model'].unique():\n",
    "    try:\n",
    "        mode_interior = df.loc[df['model'] == model, 'interior'].mode()[0]\n",
    "        df.loc[(df['interior'].isna()) & (df['model'] == model), 'interior'] = mode_interior\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "imputer = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
    "imputer = imputer.fit(df[['interior']])\n",
    "df[['interior']] = imputer.transform(df[['interior']])\n",
    "\n",
    "print('Количество пропусков в столбце interior:', df['interior'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "61b7222c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в столбце body: 12987\n",
      "Количество пропусков в столбце body: 2852\n"
     ]
    }
   ],
   "source": [
    "# заполним пропуски в столбце body наиболее популярным типом кузова для модели:\n",
    "print('Количество пропусков в столбце body:', df['body'].isna().sum())\n",
    "\n",
    "body_dict = df.groupby(['model', 'body'], as_index=False).agg({'vin':'count'}).sort_values(by='vin', ascending=False)\n",
    "body_dict = body_dict.drop_duplicates(subset='model', keep='first')\n",
    "df.loc[df['body'].isna(), 'body'] = df[df['body'].isna()]['model'].map(dict(zip(body_dict['model'], body_dict['body'])))\n",
    "\n",
    "print('Количество пропусков в столбце body:', df['body'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "92ab038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчитаем расстояние Левенштейна и объединим схожих по написанию производителей:\n",
    "columns = ['make']\n",
    "data = []\n",
    "categorical_dict = []\n",
    "\n",
    "for column in columns:\n",
    "    data = pd.DataFrame(df[column].unique()).dropna()\n",
    "    data.columns = [column]\n",
    "    for i in data[column].unique():\n",
    "        data[i] = data[column].apply(lambda x:fuzz.ratio(x, i) >= 80)\n",
    "        min_distance = np.min(data[data[i]==True][column])\n",
    "        data.loc[data[column]==i, 'group'] = min_distance\n",
    "        data = data[[f\"{column}\", 'group']]\n",
    "    categorical_dict.append(dict(zip(data[column], data['group'])))\n",
    "    \n",
    "df['make'] = df['make'].map(categorical_dict[0])\n",
    "\n",
    "# унифицируем значения в столбце make:\n",
    "df.loc[df['make'].str.contains('fordtruck', na=False), 'make'] = 'ford' \n",
    "df.loc[df['make'].str.contains('chevtruck', na=False), 'make'] = 'chevrolet'\n",
    "df.loc[df['make'].str.contains('gmctruck', na=False), 'make'] = 'gmc'\n",
    "df.loc[df['make'].str.contains('vw', na=False), 'make'] = 'volkswagen'\n",
    "df.loc[df['make'].str.contains('mercedes-benz', na=False), 'make'] = 'mercedes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b5dff4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# расчитаем расстояние Левенштейна и объединим схожие по написанию модели:\n",
    "columns = ['model']\n",
    "data = []\n",
    "categorical_dict = []\n",
    "\n",
    "for column in columns:\n",
    "    data = pd.DataFrame(df[column].unique()).dropna()\n",
    "    data.columns = [column]\n",
    "    for i in data[column].unique():\n",
    "        data[i] = data[column].apply(lambda x:fuzz.ratio(x, i) >= 90)\n",
    "        min_distance = np.min(data[data[i]==True][column])\n",
    "        data.loc[data[column]==i, 'group'] = min_distance\n",
    "        data = data[[f\"{column}\", 'group']]\n",
    "    categorical_dict.append(dict(zip(data[column], data['group'])))\n",
    "    \n",
    "df['model'] = df['model'].map(categorical_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2d53b74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_type            0\n",
       "year                 0\n",
       "make                 0\n",
       "model              176\n",
       "trim               348\n",
       "body              2852\n",
       "transmission         0\n",
       "vin                  0\n",
       "state                0\n",
       "condition            0\n",
       "odometer             0\n",
       "color                0\n",
       "interior             0\n",
       "seller               0\n",
       "sellingprice    110060\n",
       "saledate             0\n",
       "sale_year            0\n",
       "sale_month           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# изучим оставшиеся пропуски:\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "78f5efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполним пропуски в столбцах trim и body наиболее часто встречающимися значениями:\n",
    "imputer = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
    "imputer = imputer.fit(df[['trim']])\n",
    "df[['trim']] = imputer.transform(df[['trim']])\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
    "imputer = imputer.fit(df[['body']])\n",
    "df[['body']] = imputer.transform(df[['body']])\n",
    "\n",
    "# заполним пропуски  в столбце model:\n",
    "df.loc[df['model'].isna(), 'model'] = 'undefined'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f373595",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5d23ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим датафрейм на обучающую и тестовую выборки:\n",
    "train = df[df['data_type']=='train'].drop('data_type', axis=1).reset_index(drop=True)\n",
    "test = df[df['data_type']=='test'].drop('data_type', axis=1).reset_index(drop=True)\n",
    "\n",
    "# разделим выборки на матрицу признаков X и вектор целевой переменной y:\n",
    "X_train = train.drop(['sellingprice', 'vin', 'seller', 'saledate'], axis=1)\n",
    "y_train = train['sellingprice']\n",
    "X_test = test.drop(['sellingprice', 'vin', 'seller', 'saledate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0448f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем порядковое кодирование категориальных переменных:\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "\n",
    "# обучаем энкодер:\n",
    "encoder.fit(X_train[cat_features])\n",
    "\n",
    "# применяем кодировку:\n",
    "X_train[encoder.get_feature_names_out()] = encoder.transform(X_train[cat_features])\n",
    "X_test[encoder.get_feature_names_out()] = encoder.transform(X_test[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9f62f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим гиперпараметры для модели:\n",
    "n_estimators = np.arange(10, 110, 10)\n",
    "max_depth = np.arange(1, 11, 1)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59ee2335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END max_depth=1, min_samples_leaf=4, min_samples_split=5, n_estimators=10; total time=   0.3s\n",
      "[CV] END max_depth=1, min_samples_leaf=4, min_samples_split=5, n_estimators=10; total time=   3.8s\n",
      "[CV] END max_depth=1, min_samples_leaf=4, min_samples_split=5, n_estimators=30; total time=  10.9s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10; total time=   0.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=  17.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=ShuffleSplit(n_splits=1, random_state=42, test_size=0.2, train_size=None),\n",
       "                   estimator=GradientBoostingRegressor(loss=&#x27;absolute_error&#x27;,\n",
       "                                                       random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100])},\n",
       "                   random_state=42, return_train_score=True, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=ShuffleSplit(n_splits=1, random_state=42, test_size=0.2, train_size=None),\n",
       "                   estimator=GradientBoostingRegressor(loss=&#x27;absolute_error&#x27;,\n",
       "                                                       random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100])},\n",
       "                   random_state=42, return_train_score=True, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(loss=&#x27;absolute_error&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(loss=&#x27;absolute_error&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=ShuffleSplit(n_splits=1, random_state=42, test_size=0.2, train_size=None),\n",
       "                   estimator=GradientBoostingRegressor(loss='absolute_error',\n",
       "                                                       random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100])},\n",
       "                   random_state=42, return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучим модель:\n",
    "gbr = GradientBoostingRegressor(random_state=42, loss='absolute_error')\n",
    "\n",
    "model = RandomizedSearchCV(estimator=gbr, \n",
    "                           param_distributions=random_grid,\n",
    "                           n_iter = 10, \n",
    "                           cv = ShuffleSplit(test_size=0.20, n_splits=1, random_state=42), \n",
    "                           verbose=2,\n",
    "                           return_train_score=True,\n",
    "                           random_state=42, \n",
    "                           n_jobs = -1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44bd7f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.19537506346406475\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10; total time=   6.2s\n",
      "[CV] END max_depth=1, min_samples_leaf=4, min_samples_split=10, n_estimators=70; total time=  22.0s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=1, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  31.7s\n",
      "[CV] END max_depth=1, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=20; total time=  43.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END max_depth=1, min_samples_leaf=4, min_samples_split=5, n_estimators=30; total time=   0.1s\n",
      "[CV] END max_depth=4, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=80; total time=   0.3s\n",
      "[CV] END max_depth=1, min_samples_leaf=4, min_samples_split=10, n_estimators=70; total time=   0.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=90; total time= 1.8min\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=90; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=80; total time= 2.5min\n"
     ]
    }
   ],
   "source": [
    "# оценим качество модели по метрике MAPE:\n",
    "y_pred_train = model.predict(X_train)\n",
    "print('MAPE:', mean_absolute_percentage_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем модель для прогноза стоимости на тестовой выборке:\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выгрузим прогноз:\n",
    "test_df = pd.read_csv('/Users/a.babaev/Desktop/kaggle/test.csv')\n",
    "test_df = test_df[['vin']]\n",
    "final_df = test_df.join(predictions)\n",
    "final_df.columns = ['vin', 'sellingprice']\n",
    "final_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
